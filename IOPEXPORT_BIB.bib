@article{10.1088/2631-8695/adebe0,
	author={Nguyen, Viet-Thanh and Pham, Van-Truong and Tran, Thi-Thao},
	title={PHS-Net: Convolution and Transformer Dual-path with Selective Feature Fusion for Medical Image Segmentation},
	journal={Engineering Research Express},
	url={http://iopscience.iop.org/article/10.1088/2631-8695/adebe0},
	year={2025},
	abstract={Accurate segmentation of medical images is crucial for various diagnostic and therapeutic applications, yet current models often fall short in balancing the need for fine-grained local detail and comprehensive global context. To address this challenge, we introduce the Parallel Hybrid Segmentation Network called PHS-Net, a novel architecture that synergistically combines the strengths of Convolutional Neural Networks (CNNs) and Transformers. Traditional CNNs excel at capturing local patterns through convolutions, while Transformers are adept at modeling long-range dependencies through self-attention mechanisms. Our proposed PHS-Net leverages a parallel architecture, where one pathway processes input images using a full CNN and the other employs a Transformer. At each stage of the network, skip connection features from both path-ways are passed through a Selective Fusion block designed to dynamically fuse the complementary information from both representations into a unified feature map. This hybrid approach enhances the modelâ€™s ability to capture multi-scale and contextually rich features, thereby improving segmentation performance. We evaluated PHS-Net on several medical imaging benchmark datasets, demonstrating its superiority over existing models in terms of accuracy and robustness. The results indicate that our selective feature fusion mechanism effectively integrates local and global features, making PHS-Net a promising solution for complex medical image segmentation tasks. Our code will be made available.&#xD;}
}